# ğŸ‡®ğŸ‡· Persian Sentiment Analysis

An endâ€‘toâ€‘end **NLP** project for classifying **Persian (Farsi)** text into **positive / negative / neutral**.  
Includes Persianâ€‘specific preprocessing (normalization, ZWNJ handling, digit/character unification), feature extraction (**TFâ€‘IDF / embeddings**), classical ML baselines (Logistic Regression, Linear SVM, Naive Bayes), and optional **Transformer** models (ParsBERT / mBERT / XLMâ€‘R).

---

## ğŸ“– Overview
This repository implements a reproducible sentiment pipeline tailored to **Persian**:
- Text cleaning & normalization (**Arabicâ†’Persian char map**, digits, diacritics)  
- Tokenization, stopword removal, **lemmatization** (Hazm/Parsivar)  
- Feature extraction with **TFâ€‘IDF** (1â€“2/1â€“3 nâ€‘grams) or **Transformer embeddings**  
- Model training & tuning (LogReg, SVM, NB; optional ParsBERT fineâ€‘tuning)  
- Evaluation with **Accuracy, F1â€‘macro**, confusion matrix, and error analysis

---

## ğŸ—‚ï¸ Dataset
Expected CSV layout under `Dataset/`:
```
Dataset/
â”œâ”€ train.csv
â””â”€ test.csv
```
**Columns (examples):**
- `text` â€” Persian sentence/review/post  
- `label` â€” `pos` / `neg` / `neu` (or `1/0` for binary)

> You can adapt to public Persian datasets (e.g., review datasets, SentiPersâ€‘style formats). Ensure you cite the source you use.

---

## ğŸ§¹ Persianâ€‘Specific Preprocessing
- **Normalization**: convert Arabic `ÙŠ/Ùƒ` â†’ Persian `ÛŒ/Ú©`; unify digits; remove diacritics; trim extra spaces  
- **ZWNJ** (Ù†ÛŒÙ…â€ŒÙØ§ØµÙ„Ù‡): normalize halfâ€‘spaces; optionally remove for TFâ€‘IDF
- **URLs / mentions / hashtags**: strip or normalize (keep hashtag text)  
- **Tokenization & Lemmatization**: via **Hazm** (or Parsivar)  
- **Stopwords**: Persian stoplist (Hazm); extend with domainâ€‘specific words
- **Optional**: emoji mapping to sentiment tokens

---

## ğŸ§  Models
- **Logistic Regression** â€” strong linear baseline on TFâ€‘IDF  
- **Linear SVM** â€” often top classical model with sparse features  
- **Multinomial Naive Bayes** â€” fast baseline  
- **(Optional)** Transformers: **ParsBERT** (`HooshvareLab/bert-fa-base-uncased`), **mBERT**, **XLMâ€‘R**

---

## ğŸ“ˆ Evaluation (replace with your numbers)
| Model | Accuracy | F1â€‘macro |
|------|---------:|---------:|
| Logistic Regression (TFâ€‘IDF) | 0.90 | 0.89 |
| Linear SVM (TFâ€‘IDF)         | 0.92 | 0.91 |
| Naive Bayes (TFâ€‘IDF)        | 0.88 | 0.86 |
| ParsBERT (fineâ€‘tuned)       | 0.94 | 0.93 |

Export:
- Confusion matrix (3â€‘class)  
- Perâ€‘class precision/recall/F1  
- Top informative nâ€‘grams (for linear models)

---

## ğŸ§© Repository Structure (suggested)
```
Persian-Sentiment-Analysis/
â”œâ”€ Dataset/                        # train/test CSVs
â”œâ”€ Notebook/
â”‚  â””â”€ Persian_Sentiment.ipynb      # main analysis notebook
â”œâ”€ src/                            # optional scripts
â”‚  â”œâ”€ normalize_fa.py              # Persian normalizer (char map, ZWNJ, digits)
â”‚  â”œâ”€ data.py                      # loading/cleaning
â”‚  â”œâ”€ features.py                  # TF-IDF / embeddings
â”‚  â”œâ”€ train.py                     # training & tuning
â”‚  â””â”€ eval.py                      # metrics & plots
â”œâ”€ reports/figures/                # CM, PR, feature plots
â”œâ”€ requirements.txt
â”œâ”€ .gitignore
â””â”€ README.md
```

---

## âš™ï¸ Setup & Usage
1) **Clone & install**
```bash
git clone https://github.com/ziaee-mohammad/Persian-Sentiment-Analysis.git
cd Persian-Sentiment-Analysis
pip install -r requirements.txt
```

2) **Run notebook**
```bash
jupyter notebook Notebook/Persian_Sentiment.ipynb
```

3) **(Optional) Run scripts**
```bash
python -m src.train --model "svm" --ngrams 1,2 --max_features 200000
python -m src.eval  --report
```

---

## ğŸ“¦ Requirements (example)
```
pandas
numpy
scikit-learn
hazm
parsivar
nltk
matplotlib
seaborn
```
> For Transformers: add `torch` and `transformers`.

---

## âœ… Good Practices
- Use **stratified** split to preserve class ratios  
- Keep vectorizer + model in a single `Pipeline` to avoid leakage  
- Fix random seeds for reproducibility  
- Save vectorizer/model artifacts for deployment  
- Document your normalization choices (e.g., ZWNJ handling)

---

## ğŸ· Tags
```
data-science
machine-learning
nlp
sentiment-analysis
persian
farsi
text-mining
classification
tf-idf
scikit-learn
```

---

## ğŸ‘¤ Author
**Mohammad Ziaee** â€” Computer Engineer | AI & Data Science  
ğŸ“§ moha2012zia@gmail.com  
ğŸ”— https://github.com/ziaee-mohammad

---

## ğŸ“œ License
MIT â€” free to use and adapt with attribution.
